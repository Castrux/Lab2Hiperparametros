{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b8cde75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8684150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_pacientes = pd.read_csv(\"./data/Datos_Limpios_Lab1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02a79c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datos_pacientes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "442cf880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scast\\AppData\\Local\\Temp\\ipykernel_18888\\3045502807.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data[\"Date of Service\"] = pd.to_datetime(data[\"Date of Service\"], errors=\"coerce\", dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "data[\"Date of Service\"] = pd.to_datetime(data[\"Date of Service\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "data[\"Date of Service\"] = data[\"Date of Service\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Ordenar por Id y Fecha\n",
    "data = data.sort_values([\"Patient ID\", \"Date of Service\"])\n",
    "\n",
    "# Para cada Id nos quedamos con el registro m√°s reciente\n",
    "data = data.drop_duplicates(subset=\"Patient ID\", keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4710a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"CVD Risk Score\"\n",
    "X = data.drop(columns=[target])\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39a85018",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26168443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1078, 41), (1078,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b7860a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((270, 41), (270,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5ff635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"Id\", \"Fecha\", \"CodigoPostal\"]\n",
    "\n",
    "def drop_columns(df):\n",
    "    return df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "dropper = FunctionTransformer(drop_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccebb2c",
   "metadata": {},
   "source": [
    "### 1. Modelo de Regresi√≥n Polinomial\n",
    "\n",
    "## Objetivo\n",
    "Construir un pipeline que incluya generaci√≥n de caracter√≠sticas polinomiales y regresi√≥n lineal, explorando diferentes grados de polinomios y estrategias de escalamiento para identificar el punto de sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e49cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el estilo de visualizaci√≥n\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8780546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Patient ID', 'Date of Service',]\n",
    "\n",
    "def drop_columns(df):\n",
    "    return df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "dropper = FunctionTransformer(drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6cc1aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracter√≠sticas num√©ricas: ['Age', 'Weight (kg)', 'Height (m)', 'BMI', 'Abdominal Circumference (cm)', 'Total Cholesterol (mg/dL)', 'HDL (mg/dL)', 'Fasting Blood Sugar (mg/dL)', 'Height (cm)', 'Waist-to-Height Ratio', 'Systolic BP', 'Diastolic BP', 'Estimated LDL (mg/dL)', 'BMI_Age', 'BMI_Systolic', 'Age_Cholesterol', 'Systolic_Diastolic', 'Total Cholesterol (mg/dL)_log', 'Fasting Blood Sugar (mg/dL)_log', 'BMI_log', 'Age_squared', 'BMI_squared', 'Systolic BP_squared', 'Cholesterol_HDL_Ratio', 'Mean_Arterial_Pressure', 'Pulse_Pressure', 'Atherogenic_Index', 'Glucose_HDL_Ratio', 'BMI_Age_Adjusted', 'Pulse_Pressure_Age_Adjusted', 'Ponderal_Index', 'BP_Load', 'WHR_Squared', 'Lipid_Risk_Index']\n",
      "Caracter√≠sticas categ√≥ricas: ['Sex', 'Smoking Status', 'Diabetes Status', 'Physical Activity Level', 'Family History of CVD']\n",
      "Total: 39 caracter√≠sticas\n"
     ]
    }
   ],
   "source": [
    "numeric_features = [\n",
    "    'Age', 'Weight (kg)', 'Height (m)', 'BMI', 'Abdominal Circumference (cm)', \n",
    "    'Total Cholesterol (mg/dL)', 'HDL (mg/dL)', 'Fasting Blood Sugar (mg/dL)', \n",
    "    'Height (cm)', 'Waist-to-Height Ratio', 'Systolic BP', 'Diastolic BP', \n",
    "    'Estimated LDL (mg/dL)', 'BMI_Age', 'BMI_Systolic', 'Age_Cholesterol', \n",
    "    'Systolic_Diastolic', 'Total Cholesterol (mg/dL)_log', \n",
    "    'Fasting Blood Sugar (mg/dL)_log', 'BMI_log', 'Age_squared', 'BMI_squared', \n",
    "    'Systolic BP_squared', 'Cholesterol_HDL_Ratio', 'Mean_Arterial_Pressure', \n",
    "    'Pulse_Pressure', 'Atherogenic_Index', 'Glucose_HDL_Ratio', 'BMI_Age_Adjusted', \n",
    "    'Pulse_Pressure_Age_Adjusted', 'Ponderal_Index', 'BP_Load', 'WHR_Squared', \n",
    "    'Lipid_Risk_Index'\n",
    "]\n",
    "\n",
    "categorical_features = [ \n",
    "    'Sex', 'Smoking Status', 'Diabetes Status', 'Physical Activity Level', \n",
    "    'Family History of CVD'\n",
    "]\n",
    "\n",
    "print(f\"Caracter√≠sticas num√©ricas: {numeric_features}\")\n",
    "print(f\"Caracter√≠sticas categ√≥ricas: {categorical_features}\")  \n",
    "print(f\"Total: {len(numeric_features) + len(categorical_features)} caracter√≠sticas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91d1e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transforme_polinomial = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"polynomial\", PolynomialFeatures(degree=2)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ed3175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_polinomial = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transforme_polinomial, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "987cc65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_regresion_polinomial = Pipeline(steps=[\n",
    "    (\"dropper\", dropper),\n",
    "    (\"preprocesamiento\", preprocessor_polinomial),\n",
    "    (\"modelo\", LinearRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58b0a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir par√°metros para GridSearchCV\n",
    "param_grid = {\n",
    "    'preprocesamiento__num__scaler': [StandardScaler(), None],\n",
    "    'preprocesamiento__num__polynomial__degree': [2, 3, 4, 5],  # Grado del polinomio\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "863e052d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando b√∫squeda exhaustiva de hiperpar√°metros...\n",
      "Combinaciones a evaluar: 8 √ó 5 folds\n"
     ]
    }
   ],
   "source": [
    "# Crear GridSearchCV con validaci√≥n cruzada (5 folds)\n",
    "grid = GridSearchCV(\n",
    "    pipeline_regresion_polinomial,\n",
    "    param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,  # Usar todos los cores disponibles\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Iniciando b√∫squeda exhaustiva de hiperpar√°metros...\")\n",
    "print(f\"Combinaciones a evaluar: {len(param_grid['preprocesamiento__num__scaler']) * len(param_grid['preprocesamiento__num__polynomial__degree'])} √ó 5 folds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a2abc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "6 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 662, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 682, in fit\n",
      "    self.coef_, _, self.rank_, self.singular_ = linalg.lstsq(X, y, cond=cond)\n",
      "                                                ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\scipy\\_lib\\_util.py\", line 1233, in wrapper\n",
      "    return f(*arrays, *other_args, **kwargs)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\scipy\\linalg\\_basic.py\", line 1495, in lstsq\n",
      "    x, s, rank, info = lapack_func(a1, b1, lwork,\n",
      "                       ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "                                   iwork, cond, False, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 3.70 GiB for an array with shape (863, 575764) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 662, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 682, in fit\n",
      "    self.coef_, _, self.rank_, self.singular_ = linalg.lstsq(X, y, cond=cond)\n",
      "                                                ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\scipy\\_lib\\_util.py\", line 1233, in wrapper\n",
      "    return f(*arrays, *other_args, **kwargs)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\scipy\\linalg\\_basic.py\", line 1495, in lstsq\n",
      "    x, s, rank, info = lapack_func(a1, b1, lwork,\n",
      "                       ~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "                                   iwork, cond, False, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 3.70 GiB for an array with shape (862, 575764) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        cloned_transformer,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        params=step_params,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1031, in fit_transform\n",
      "    return self._hstack(list(Xs), n_samples=n_samples)\n",
      "           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1225, in _hstack\n",
      "    return np.hstack(Xs)\n",
      "           ~~~~~~~~~^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\numpy\\_core\\shape_base.py\", line 367, in hstack\n",
      "    return _nx.concatenate(arrs, 1, dtype=dtype, casting=casting)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 3.70 GiB for an array with shape (862, 575764) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        cloned_transformer,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        params=step_params,\n",
      "        ^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1031, in fit_transform\n",
      "    return self._hstack(list(Xs), n_samples=n_samples)\n",
      "           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1225, in _hstack\n",
      "    return np.hstack(Xs)\n",
      "           ~~~~~~~~~^^^^\n",
      "  File \"c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\numpy\\_core\\shape_base.py\", line 367, in hstack\n",
      "    return _nx.concatenate(arrs, 1, dtype=dtype, casting=casting)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 3.70 GiB for an array with shape (863, 575764) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\scast\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [-4.01760315e+09 -8.63700969e+09 -1.83195533e+07 -2.79095865e+08\n",
      " -2.16461332e+09 -1.82151278e+08             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "B√∫squeda completada en 5 folds\n",
      "\n",
      "Mejores hiperpar√°metros encontrados:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'scaler'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mB√∫squeda completada en \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid\u001b[38;5;241m.\u001b[39mn_splits_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m folds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMejores hiperpar√°metros encontrados:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Escalador: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid\u001b[38;5;241m.\u001b[39mbest_params_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mgrid\u001b[38;5;241m.\u001b[39mbest_params_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNinguno (Sin escalamiento)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Grado del polinomio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid\u001b[38;5;241m.\u001b[39mbest_params_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly_features__degree\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMejor RMSE en validaci√≥n cruzada: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msqrt(\u001b[38;5;241m-\u001b[39mgrid\u001b[38;5;241m.\u001b[39mbest_score_)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'scaler'"
     ]
    }
   ],
   "source": [
    "# 1.2 Ejecutar GridSearchCV\n",
    "grid.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31245f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nB√∫squeda completada en {grid.n_splits_} folds\")\n",
    "print(f\"\\nMejores hiperpar√°metros encontrados:\")\n",
    "print(f\"  - Escalador: {grid.best_params_['scaler'].__class__.__name__ if grid.best_params_['scaler'] is not None else 'Ninguno (Sin escalamiento)'}\")\n",
    "print(f\"  - Grado del polinomio: {grid.best_params_['poly_features__degree']}\")\n",
    "print(f\"\\nMejor RMSE en validaci√≥n cruzada: {sqrt(-grid.best_score_):.4f}\")\n",
    "print(f\"Mejor MSE en validaci√≥n cruzada: {-grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d24d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "M√âTRICAS DEL MEJOR MODELO DE REGRESI√ìN POLINOMIAL\n",
      "======================================================================\n",
      "         Train       Test  Diferencia (Train - Test)\n",
      "RMSE   10.7183    46.3887                   -35.6704\n",
      "MAE     3.5530     6.1398                    -2.5868\n",
      "R¬≤      0.0524   -18.7073                    18.7597\n",
      "MSE   114.8828  2151.9159                 -2037.0331\n",
      "======================================================================\n",
      "\n",
      "üìä An√°lisis de Sobreajuste:\n",
      "  - Diferencia RMSE (Train - Test): -35.6704\n",
      "    ‚Üí El modelo generaliza MEJOR en Test (posible subajuste)\n",
      "  - Diferencia R¬≤ (Train - Test): 18.7597\n",
      "    ‚Üí CONFIRMADO: Hay sobreajuste significativo\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Evaluar el mejor modelo en train y test\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Predicciones\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Funci√≥n para calcular m√©tricas\n",
    "def calculate_metrics(y_true, y_pred, set_name=\"\"):\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R¬≤': r2,\n",
    "        'MSE': mse\n",
    "    }\n",
    "\n",
    "metrics_train = calculate_metrics(y_train, y_train_pred, \"Train\")\n",
    "metrics_test = calculate_metrics(y_test, y_test_pred, \"Test\")\n",
    "\n",
    "# Crear tabla comparativa\n",
    "results_df = pd.DataFrame({\n",
    "    'Train': metrics_train,\n",
    "    'Test': metrics_test,\n",
    "    'Diferencia (Train - Test)': {k: metrics_train[k] - metrics_test[k] for k in metrics_train.keys()}\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"M√âTRICAS DEL MEJOR MODELO DE REGRESI√ìN POLINOMIAL\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.round(4))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Analizar sobreajuste\n",
    "diff_rmse = metrics_train['RMSE'] - metrics_test['RMSE']\n",
    "diff_r2 = metrics_train['R¬≤'] - metrics_test['R¬≤']\n",
    "\n",
    "print(f\"\\nüìä An√°lisis de Sobreajuste:\")\n",
    "print(f\"  - Diferencia RMSE (Train - Test): {diff_rmse:.4f}\")\n",
    "if diff_rmse < 0:\n",
    "    print(f\"    ‚Üí El modelo generaliza MEJOR en Test (posible subajuste)\")\n",
    "elif diff_rmse > 0.1:\n",
    "    print(f\"    ‚Üí Hay indicios de SOBREAJUSTE\")\n",
    "else:\n",
    "    print(f\"    ‚Üí El modelo tiene buena generalizaci√≥n\")\n",
    "    \n",
    "print(f\"  - Diferencia R¬≤ (Train - Test): {diff_r2:.4f}\")\n",
    "if diff_r2 > 0.1:\n",
    "    print(f\"    ‚Üí CONFIRMADO: Hay sobreajuste significativo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a66066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 An√°lisis detallado: Desempe√±o por grado polinomial\n",
    "\n",
    "# Extraer resultados de GridSearchCV\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# Agrupar por grado del polinomio\n",
    "polynomial_degrees = cv_results['param_poly_features__degree'].unique()\n",
    "polynomial_degrees.sort()\n",
    "\n",
    "# Para cada grado, calcular estad√≠sticas\n",
    "polynomial_performance = []\n",
    "\n",
    "for degree in polynomial_degrees:\n",
    "    degree_results = cv_results[cv_results['param_poly_features__degree'] == degree]\n",
    "    \n",
    "    cv_rmse_mean = sqrt(-degree_results['mean_test_score'].values[0])\n",
    "    cv_rmse_std = sqrt(degree_results['std_test_score'].values[0])\n",
    "    \n",
    "    # Entrenar modelo con este grado para evaluar en test\n",
    "    scaler_with_scale = degree_results['param_scaler'].values[0]\n",
    "    \n",
    "    # Crear pipeline temporal para este grado\n",
    "    temp_pipeline = Pipeline([\n",
    "        ('scaler', scaler_with_scale if scaler_with_scale is not None else StandardScaler()),\n",
    "        ('poly_features', PolynomialFeatures(degree=degree)),\n",
    "        ('regression', LinearRegression())\n",
    "    ])\n",
    "    \n",
    "    temp_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred_temp = temp_pipeline.predict(X_train)\n",
    "    y_test_pred_temp = temp_pipeline.predict(X_test)\n",
    "    \n",
    "    train_rmse = sqrt(mean_squared_error(y_train, y_train_pred_temp))\n",
    "    test_rmse = sqrt(mean_squared_error(y_test, y_test_pred_temp))\n",
    "    train_r2 = r2_score(y_train, y_train_pred_temp)\n",
    "    test_r2 = r2_score(y_test, y_test_pred_temp)\n",
    "    \n",
    "    polynomial_performance.append({\n",
    "        'Degree': degree,\n",
    "        'CV_RMSE_Mean': cv_rmse_mean,\n",
    "        'CV_RMSE_Std': cv_rmse_std,\n",
    "        'Train_RMSE': train_rmse,\n",
    "        'Test_RMSE': test_rmse,\n",
    "        'Train_R¬≤': train_r2,\n",
    "        'Test_R¬≤': test_r2,\n",
    "        'Overfitting_Gap': train_rmse - test_rmse\n",
    "    })\n",
    "\n",
    "poly_performance_df = pd.DataFrame(polynomial_performance)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"AN√ÅLISIS DE DESEMPE√ëO POR GRADO POLINOMIAL\")\n",
    "print(\"=\"*100)\n",
    "print(poly_performance_df.round(4))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa730d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Visualizaci√≥n 1: Curvas de Validaci√≥n - RMSE por Grado Polinomial\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Gr√°fico 1: RMSE (CV, Train, Test)\n",
    "ax1 = axes[0, 0]\n",
    "ax1.errorbar(poly_performance_df['Degree'], poly_performance_df['CV_RMSE_Mean'], \n",
    "             yerr=poly_performance_df['CV_RMSE_Std'], marker='o', label='CV RMSE (¬±std)', linewidth=2, capsize=5)\n",
    "ax1.plot(poly_performance_df['Degree'], poly_performance_df['Train_RMSE'], \n",
    "         marker='s', label='Train RMSE', linewidth=2)\n",
    "ax1.plot(poly_performance_df['Degree'], poly_performance_df['Test_RMSE'], \n",
    "         marker='^', label='Test RMSE', linewidth=2)\n",
    "ax1.set_xlabel('Grado del Polinomio', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('RMSE', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Curva de Validaci√≥n: RMSE vs Grado Polinomial', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xticks(poly_performance_df['Degree'])\n",
    "\n",
    "# Gr√°fico 2: R¬≤ (Train, Test)\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(poly_performance_df['Degree'], poly_performance_df['Train_R¬≤'], \n",
    "         marker='s', label='Train R¬≤', linewidth=2, markersize=8)\n",
    "ax2.plot(poly_performance_df['Degree'], poly_performance_df['Test_R¬≤'], \n",
    "         marker='^', label='Test R¬≤', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Grado del Polinomio', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('R¬≤ Score', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Coeficiente de Determinaci√≥n (R¬≤) vs Grado Polinomial', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xticks(poly_performance_df['Degree'])\n",
    "\n",
    "# Gr√°fico 3: Brecha de Sobreajuste\n",
    "ax3 = axes[1, 0]\n",
    "colors = ['green' if gap < 0.05 else 'orange' if gap < 0.15 else 'red' \n",
    "          for gap in poly_performance_df['Overfitting_Gap']]\n",
    "ax3.bar(poly_performance_df['Degree'], poly_performance_df['Overfitting_Gap'], \n",
    "        color=colors, alpha=0.7, edgecolor='black')\n",
    "ax3.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "ax3.set_xlabel('Grado del Polinomio', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Train RMSE - Test RMSE', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Brecha de Sobreajuste (Train - Test RMSE)', fontsize=12, fontweight='bold')\n",
    "ax3.set_xticks(poly_performance_df['Degree'])\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Gr√°fico 4: Variabilidad en Validaci√≥n Cruzada\n",
    "ax4 = axes[1, 1]\n",
    "ax4.bar(poly_performance_df['Degree'], poly_performance_df['CV_RMSE_Std'], \n",
    "        color='skyblue', alpha=0.7, edgecolor='black')\n",
    "ax4.set_xlabel('Grado del Polinomio', fontsize=11, fontweight='bold')\n",
    "ax4.set_ylabel('Desv. Est. del RMSE en CV', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('Estabilidad del Modelo: Variabilidad en Validaci√≥n Cruzada', fontsize=12, fontweight='bold')\n",
    "ax4.set_xticks(poly_performance_df['Degree'])\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./outputs/01_polynomial_curves.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Gr√°fico guardado: ./outputs/01_polynomial_curves.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80094e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpeta de outputs si no existe\n",
    "import os\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "print(\"‚úì Carpeta de outputs lista\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beeca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6 Visualizaci√≥n 2: An√°lisis de Residuos del Mejor Modelo\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Residuos\n",
    "train_residuals = y_train - y_train_pred\n",
    "test_residuals = y_test - y_test_pred\n",
    "\n",
    "# Gr√°fico 1: Predicciones vs Valores Reales (Train)\n",
    "ax1 = axes[0, 0]\n",
    "ax1.scatter(y_train, y_train_pred, alpha=0.5, s=30, label='Predicciones')\n",
    "min_val = min(y_train.min(), y_test.min())\n",
    "max_val = max(y_train.max(), y_test.max())\n",
    "ax1.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='L√≠nea Perfecta')\n",
    "ax1.set_xlabel('Valores Reales', fontsize=11, fontweight='bold')\n",
    "ax1.set_ylabel('Predicciones', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Conjunto de Entrenamiento: Predicciones vs Reales', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico 2: Predicciones vs Valores Reales (Test)\n",
    "ax2 = axes[0, 1]\n",
    "ax2.scatter(y_test, y_test_pred, alpha=0.5, s=30, color='orange', label='Predicciones')\n",
    "ax2.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='L√≠nea Perfecta')\n",
    "ax2.set_xlabel('Valores Reales', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('Predicciones', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Conjunto de Test: Predicciones vs Reales', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico 3: Distribuci√≥n de Residuos (Train)\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(train_residuals, bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "ax3.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "ax3.set_xlabel('Residuos', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Frecuencia', fontsize=11, fontweight='bold')\n",
    "ax3.set_title(f'Distribuci√≥n de Residuos - Entrenamiento\\nMedia: {train_residuals.mean():.4f}, Std: {train_residuals.std():.4f}', \n",
    "              fontsize=11, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Gr√°fico 4: Distribuci√≥n de Residuos (Test)\n",
    "ax4 = axes[1, 1]\n",
    "ax4.hist(test_residuals, bins=30, alpha=0.7, color='orange', edgecolor='black')\n",
    "ax4.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "ax4.set_xlabel('Residuos', fontsize=11, fontweight='bold')\n",
    "ax4.set_ylabel('Frecuencia', fontsize=11, fontweight='bold')\n",
    "ax4.set_title(f'Distribuci√≥n de Residuos - Test\\nMedia: {test_residuals.mean():.4f}, Std: {test_residuals.std():.4f}', \n",
    "              fontsize=11, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./outputs/02_residuals_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Gr√°fico guardado: ./outputs/02_residuals_analysis.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818469b0",
   "metadata": {},
   "source": [
    "## 1.7 Conclusiones del An√°lisis de Complejidad y Sobreajuste\n",
    "\n",
    "### Interpretaci√≥n de Resultados\n",
    "\n",
    "**Trade-off Sesgo-Varianza:**\n",
    "- Los modelos con bajo grado polinomial (grado 1-2) tienden a tener **alto sesgo** pero **baja varianza** (subajuste)\n",
    "- Los modelos de alto grado (grado 6-7) tienden a tener **bajo sesgo** pero **alta varianza** (sobreajuste)\n",
    "- El mejor desempe√±o se encuentra en el punto √≥ptimo que minimiza el error total\n",
    "\n",
    "**Indicadores de Sobreajuste:**\n",
    "1. **Brecha RMSE (Train - Test)**: Una diferencia significativa indica que el modelo memoriza los datos de entrenamiento\n",
    "2. **Divergencia de R¬≤**: Si R¬≤ en train es mucho mayor que en test, hay sobreajuste\n",
    "3. **Variabilidad en CV**: Alta desviaci√≥n est√°ndar en validaci√≥n cruzada sugiere inestabilidad del modelo\n",
    "\n",
    "**Recomendaciones:**\n",
    "- Seleccionar el modelo con el mejor compromiso entre desempe√±o en CV y estabilidad\n",
    "- Considerar la complejidad: un modelo m√°s simple que generaliza bien es preferible a uno complejo que sobreajusta\n",
    "- Validar las decisiones considerando interpretabilidad y costo computacional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.8 Resumen Final del Modelo Polinomial\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN EJECUTIVO: MODELO DE REGRESI√ìN POLINOMIAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_degree = grid_search.best_params_['poly_features__degree']\n",
    "best_scaler = grid_search.best_params_['scaler']\n",
    "\n",
    "print(f\"\\n‚úì MEJOR CONFIGURACI√ìN ENCONTRADA:\")\n",
    "print(f\"  - Grado del Polinomio: {best_degree}\")\n",
    "print(f\"  - Escalador: {'StandardScaler' if best_scaler is not None else 'Ninguno (sin escalamiento)'}\")\n",
    "\n",
    "print(f\"\\n‚úì DESEMPE√ëO DEL MEJOR MODELO:\")\n",
    "print(f\"  En Validaci√≥n Cruzada (5-folds):\")\n",
    "print(f\"    - RMSE medio: {sqrt(-grid_search.best_score_):.6f}\")\n",
    "print(f\"    - MSE medio: {-grid_search.best_score_:.6f}\")\n",
    "\n",
    "print(f\"\\n  En Conjunto de Entrenamiento:\")\n",
    "print(f\"    - RMSE: {metrics_train['RMSE']:.6f}\")\n",
    "print(f\"    - MAE:  {metrics_train['MAE']:.6f}\")\n",
    "print(f\"    - R¬≤:   {metrics_train['R¬≤']:.6f}\")\n",
    "\n",
    "print(f\"\\n  En Conjunto de Test:\")\n",
    "print(f\"    - RMSE: {metrics_test['RMSE']:.6f}\")\n",
    "print(f\"    - MAE:  {metrics_test['MAE']:.6f}\")\n",
    "print(f\"    - R¬≤:   {metrics_test['R¬≤']:.6f}\")\n",
    "\n",
    "print(f\"\\n‚úì AN√ÅLISIS DE GENERALIZACI√ìN:\")\n",
    "rmse_gap = metrics_train['RMSE'] - metrics_test['RMSE']\n",
    "r2_gap = metrics_train['R¬≤'] - metrics_test['R¬≤']\n",
    "\n",
    "print(f\"  - Diferencia RMSE (Train - Test): {rmse_gap:.6f}\")\n",
    "print(f\"  - Diferencia R¬≤ (Train - Test): {r2_gap:.6f}\")\n",
    "\n",
    "if rmse_gap > 0.1 or r2_gap > 0.05:\n",
    "    print(f\"  ‚ö†Ô∏è  ADVERTENCIA: Indicios de sobreajuste detectados\")\n",
    "else:\n",
    "    print(f\"  ‚úì Buen balance entre entrenamiento y generalizaci√≥n\")\n",
    "\n",
    "print(f\"\\n‚úì N√öMERO DE CARACTER√çSTICAS:\")\n",
    "# Contar caracter√≠sticas despu√©s de PolynomialFeatures\n",
    "n_features_original = X_train.shape[1]\n",
    "poly_transformer = best_model.named_steps['poly_features']\n",
    "n_features_polynomial = poly_transformer.n_output_features_\n",
    "print(f\"  - Caracter√≠sticas originales: {n_features_original}\")\n",
    "print(f\"  - Caracter√≠sticas polinomiales (grado {best_degree}): {n_features_polynomial}\")\n",
    "print(f\"  - Aumento: {n_features_polynomial / n_features_original:.1f}x\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Guardar informaci√≥n del modelo\n",
    "model_info = {\n",
    "    'model_type': 'Polynomial Regression',\n",
    "    'best_degree': best_degree,\n",
    "    'n_features_original': n_features_original,\n",
    "    'n_features_polynomial': n_features_polynomial,\n",
    "    'test_rmse': metrics_test['RMSE'],\n",
    "    'test_mae': metrics_test['MAE'],\n",
    "    'test_r2': metrics_test['R¬≤'],\n",
    "    'cv_rmse': sqrt(-grid_search.best_score_)\n",
    "}\n",
    "\n",
    "print(\"‚úì Informaci√≥n del modelo guardada para comparaci√≥n futura\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
